\chapter{Design and Implementation}

After researching literature on building libraries from scratch, and analyzing pet project source-codes \cite{convnetjs, gibianskysource} and implementations of industrial APIs \cite{TF, caffe, torch}
I concluded that the best way to acquire that knowledge is to build my own Deep Learning framework.
This way I had a chance to understand why novel solutions in Machine Learning are formed the way they are.
Also gained insight into what main paradigms are popular libraries based on, such as \emph{computational graphs, parallel distributed processings}, 
and what trade-offs can be made between \emph{computational cost} and \emph{memory usage}, between robustness and plasticity.
Most thankfully, by starting from scratch I have faced challenges of situations when theoretical formulas has to be transformed into exact working code, which roughly speaking is the hardest part of modern science.


